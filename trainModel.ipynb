{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader  \n",
    "from torchvision import datasets, models, transforms\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Definindo dispositivo de hardware\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # Ajuste o tamanho conforme necessário\n",
    "    transforms.RandomResizedCrop (224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485], [0.229]) #é Normalização de imagem em tons de cinza\n",
    "])\n",
    "\n",
    "transforms_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # Ajuste o tamanho conforme necessário\n",
    "    transforms.CenterCrop((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485], [0.229]) # Normalização de imagem em tons de cinza\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"/Datafol/trainfol/\"\n",
    "test_dir = \"/Datafol/testfol/\"\n",
    "train_classa_dir = \"/Datafol/trainfol/classafol/\"\n",
    "train_classb_dir = \"/Datafol/trainfol/classbfol/\"\n",
    "test_classa_dir = \"/Datafol/testfol/classafol/\"\n",
    "test_classb_dir = \"/Datafol/testfol/classbfol/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = ('/home/arthur/Projetos/SPLIT_IMG/test')\n",
    "train_dir = ('/home/arthur/Projetos/SPLIT_IMG/train')\n",
    "train_dataset = datasets.ImageFolder(train_dir, transforms_train)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transforms_test)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=12, shuffle=True, num_workers=1)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=12, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinar o tamanho do conjunto de dado 4487\n",
      "Testar o tamanho do conjunto de dados 2335\n",
      "Nomes de classe: ['-1', '-2', '-3', '0', '1', '2', '3']\n"
     ]
    }
   ],
   "source": [
    "print('Treinar o tamanho do conjunto de dado', len(train_dataset))\n",
    "print('Testar o tamanho do conjunto de dados', len(test_dataset))\n",
    "class_names = train_dataset.classes\n",
    "print('Nomes de classe:', class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthur/anaconda3/envs/skincancer/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/arthur/anaconda3/envs/skincancer/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True) # carrregando rede. resnet18 model\n",
    "num_features = model.fc.in_features # extraindo features da camada fc\n",
    "model.fc = nn.Linear(num_features, 7) # é numero de classes\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() #(set. loss: function)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_accs = []\n",
    "train_precisions = []\n",
    "train_recalls = []\n",
    "test_losses = []\n",
    "test_accs = []\n",
    "test_precisions = []\n",
    "test_recalls = []\n",
    "num_epochs = 100 # define o número de epochs\n",
    "start_time = time.time() # calcular o tempo de cada época"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 running\n",
      "[Train #0] Loss: 1.2692 Acc: 52.1729% Time: 29.3587s\n",
      "[Test #0] Loss: 0.9397 Acc: 63.9400% Time: 36.8515s\n",
      "Epoch 1 running\n",
      "[Train #1] Loss: 1.0018 Acc: 62.4916% Time: 63.6849s\n",
      "[Test #1] Loss: 0.8851 Acc: 67.0236% Time: 70.4038s\n",
      "Epoch 2 running\n",
      "[Train #2] Loss: 0.9492 Acc: 64.4974% Time: 97.3059s\n",
      "[Test #2] Loss: 0.9782 Acc: 65.6531% Time: 104.3053s\n",
      "Epoch 3 running\n",
      "[Train #3] Loss: 0.8734 Acc: 67.3947% Time: 131.6143s\n",
      "[Test #3] Loss: 0.6923 Acc: 74.6467% Time: 138.6102s\n",
      "Epoch 4 running\n",
      "[Train #4] Loss: 0.8140 Acc: 69.8908% Time: 166.1383s\n",
      "[Test #4] Loss: 0.7340 Acc: 72.8051% Time: 172.9590s\n",
      "Epoch 5 running\n",
      "[Train #5] Loss: 0.7732 Acc: 70.9605% Time: 200.7756s\n",
      "[Test #5] Loss: 0.6240 Acc: 77.2163% Time: 207.6953s\n",
      "Epoch 6 running\n",
      "[Train #6] Loss: 0.7223 Acc: 73.2115% Time: 235.7910s\n",
      "[Test #6] Loss: 0.6768 Acc: 75.4176% Time: 242.8536s\n",
      "Epoch 7 running\n",
      "[Train #7] Loss: 0.6966 Acc: 74.4595% Time: 270.8040s\n",
      "[Test #7] Loss: 0.6435 Acc: 77.6445% Time: 277.5705s\n",
      "Epoch 8 running\n",
      "[Train #8] Loss: 0.6753 Acc: 75.1059% Time: 305.6984s\n",
      "[Test #8] Loss: 0.6965 Acc: 75.7602% Time: 312.6585s\n",
      "Epoch 9 running\n",
      "[Train #9] Loss: 0.6524 Acc: 75.8190% Time: 340.8756s\n",
      "[Test #9] Loss: 0.7782 Acc: 73.7045% Time: 347.7772s\n",
      "Epoch 10 running\n",
      "[Train #10] Loss: 0.6174 Acc: 77.3345% Time: 376.4823s\n",
      "[Test #10] Loss: 0.6700 Acc: 75.9315% Time: 384.1522s\n",
      "Epoch 11 running\n",
      "[Train #11] Loss: 0.5714 Acc: 78.4043% Time: 412.8567s\n",
      "[Test #11] Loss: 0.7753 Acc: 73.2334% Time: 419.7027s\n",
      "Epoch 12 running\n",
      "[Train #12] Loss: 0.5756 Acc: 78.8277% Time: 448.0274s\n",
      "[Test #12] Loss: 0.8123 Acc: 74.0899% Time: 454.6418s\n",
      "Epoch 13 running\n",
      "[Train #13] Loss: 0.5510 Acc: 79.8306% Time: 483.0300s\n",
      "[Test #13] Loss: 0.6281 Acc: 78.4582% Time: 489.7672s\n",
      "Epoch 14 running\n",
      "[Train #14] Loss: 0.5415 Acc: 79.3849% Time: 518.3222s\n",
      "[Test #14] Loss: 0.6791 Acc: 77.4732% Time: 524.8359s\n",
      "Epoch 15 running\n",
      "[Train #15] Loss: 0.5027 Acc: 81.7918% Time: 553.2246s\n",
      "[Test #15] Loss: 0.6742 Acc: 77.6017% Time: 559.8658s\n",
      "Epoch 16 running\n",
      "[Train #16] Loss: 0.5154 Acc: 80.4547% Time: 588.3454s\n",
      "[Test #16] Loss: 0.6249 Acc: 78.6724% Time: 594.9455s\n",
      "Epoch 17 running\n",
      "[Train #17] Loss: 0.5251 Acc: 80.6775% Time: 623.4453s\n",
      "[Test #17] Loss: 0.6116 Acc: 78.6724% Time: 630.1278s\n",
      "Epoch 18 running\n",
      "[Train #18] Loss: 0.4746 Acc: 82.5942% Time: 658.7716s\n",
      "[Test #18] Loss: 0.7192 Acc: 77.0450% Time: 665.1275s\n",
      "Epoch 19 running\n",
      "[Train #19] Loss: 0.4861 Acc: 82.4382% Time: 693.4942s\n",
      "[Test #19] Loss: 0.7655 Acc: 74.3469% Time: 699.9040s\n",
      "Epoch 20 running\n",
      "[Train #20] Loss: 0.4456 Acc: 83.5302% Time: 727.9378s\n",
      "[Test #20] Loss: 0.6497 Acc: 79.4004% Time: 733.2769s\n",
      "Epoch 21 running\n",
      "[Train #21] Loss: 0.4509 Acc: 83.2182% Time: 760.0418s\n",
      "[Test #21] Loss: 0.6138 Acc: 80.5996% Time: 765.4156s\n",
      "Epoch 22 running\n",
      "[Train #22] Loss: 0.4422 Acc: 83.6416% Time: 792.0164s\n",
      "[Test #22] Loss: 0.6011 Acc: 81.6274% Time: 797.3113s\n",
      "Epoch 23 running\n",
      "[Train #23] Loss: 0.4163 Acc: 85.1348% Time: 823.7155s\n",
      "[Test #23] Loss: 0.7006 Acc: 79.2719% Time: 828.9254s\n",
      "Epoch 24 running\n",
      "[Train #24] Loss: 0.4012 Acc: 85.8480% Time: 855.5808s\n",
      "[Test #24] Loss: 0.6964 Acc: 78.5011% Time: 860.6971s\n",
      "Epoch 25 running\n",
      "[Train #25] Loss: 0.4053 Acc: 85.3577% Time: 887.0841s\n",
      "[Test #25] Loss: 0.6655 Acc: 79.7430% Time: 892.3372s\n",
      "Epoch 26 running\n",
      "[Train #26] Loss: 0.3856 Acc: 85.8257% Time: 918.6504s\n",
      "[Test #26] Loss: 0.6280 Acc: 81.4989% Time: 923.7234s\n",
      "Epoch 27 running\n",
      "[Train #27] Loss: 0.3712 Acc: 86.3606% Time: 950.2874s\n",
      "[Test #27] Loss: 0.6293 Acc: 79.5289% Time: 955.4152s\n",
      "Epoch 28 running\n",
      "[Train #28] Loss: 0.3909 Acc: 85.7366% Time: 981.9285s\n",
      "[Test #28] Loss: 0.6703 Acc: 79.7430% Time: 987.0475s\n",
      "Epoch 29 running\n",
      "[Train #29] Loss: 0.3594 Acc: 87.1406% Time: 1013.5878s\n",
      "[Test #29] Loss: 0.7965 Acc: 77.6445% Time: 1018.8135s\n",
      "Epoch 30 running\n",
      "[Train #30] Loss: 0.3620 Acc: 86.8063% Time: 1046.6278s\n",
      "[Test #30] Loss: 0.7758 Acc: 79.4004% Time: 1054.2039s\n",
      "Epoch 31 running\n",
      "[Train #31] Loss: 0.3598 Acc: 86.6726% Time: 1083.2509s\n",
      "[Test #31] Loss: 0.6711 Acc: 79.3576% Time: 1091.6429s\n",
      "Epoch 32 running\n",
      "[Train #32] Loss: 0.3581 Acc: 87.2075% Time: 1121.8951s\n",
      "[Test #32] Loss: 0.7291 Acc: 79.6574% Time: 1130.2935s\n",
      "Epoch 33 running\n",
      "[Train #33] Loss: 0.3326 Acc: 88.0321% Time: 1159.3155s\n",
      "[Test #33] Loss: 0.7661 Acc: 79.0578% Time: 1166.4262s\n",
      "Epoch 34 running\n",
      "[Train #34] Loss: 0.3244 Acc: 88.2104% Time: 1195.9710s\n",
      "[Test #34] Loss: 0.6827 Acc: 81.1563% Time: 1206.2037s\n",
      "Epoch 35 running\n",
      "[Train #35] Loss: 0.3436 Acc: 87.7869% Time: 1249.8897s\n",
      "[Test #35] Loss: 0.6245 Acc: 81.6702% Time: 1256.4489s\n",
      "Epoch 36 running\n",
      "[Train #36] Loss: 0.3129 Acc: 88.8344% Time: 1285.4082s\n",
      "[Test #36] Loss: 0.6973 Acc: 81.1135% Time: 1292.1272s\n",
      "Epoch 37 running\n",
      "[Train #37] Loss: 0.3122 Acc: 88.7676% Time: 1320.8572s\n",
      "[Test #37] Loss: 0.7519 Acc: 81.0707% Time: 1327.7759s\n",
      "Epoch 38 running\n",
      "[Train #38] Loss: 0.3071 Acc: 88.7898% Time: 1356.3550s\n",
      "[Test #38] Loss: 0.6879 Acc: 81.5418% Time: 1363.1066s\n",
      "Epoch 39 running\n",
      "[Train #39] Loss: 0.2926 Acc: 89.3693% Time: 1392.0152s\n",
      "[Test #39] Loss: 0.6678 Acc: 82.0128% Time: 1398.9451s\n",
      "Epoch 40 running\n",
      "[Train #40] Loss: 0.3135 Acc: 89.1464% Time: 1427.7451s\n",
      "[Test #40] Loss: 0.6565 Acc: 81.7559% Time: 1435.3055s\n",
      "Epoch 41 running\n",
      "[Train #41] Loss: 0.3101 Acc: 89.3693% Time: 1464.2610s\n",
      "[Test #41] Loss: 0.7579 Acc: 79.4861% Time: 1471.2042s\n",
      "Epoch 42 running\n",
      "[Train #42] Loss: 0.2890 Acc: 89.4584% Time: 1500.1121s\n",
      "[Test #42] Loss: 0.7071 Acc: 80.1285% Time: 1506.8683s\n",
      "Epoch 43 running\n",
      "[Train #43] Loss: 0.2930 Acc: 89.5476% Time: 1535.6729s\n",
      "[Test #43] Loss: 0.7232 Acc: 81.6274% Time: 1542.4055s\n",
      "Epoch 44 running\n",
      "[Train #44] Loss: 0.3059 Acc: 89.2356% Time: 1571.5384s\n",
      "[Test #44] Loss: 0.6825 Acc: 82.5268% Time: 1578.8019s\n",
      "Epoch 45 running\n",
      "[Train #45] Loss: 0.2742 Acc: 90.6619% Time: 1608.8035s\n",
      "[Test #45] Loss: 0.7534 Acc: 81.5846% Time: 1616.2513s\n",
      "Epoch 46 running\n",
      "[Train #46] Loss: 0.2624 Acc: 91.0185% Time: 1645.0879s\n",
      "[Test #46] Loss: 0.6820 Acc: 82.6124% Time: 1651.6454s\n",
      "Epoch 47 running\n",
      "[Train #47] Loss: 0.2835 Acc: 89.8596% Time: 1716.9666s\n",
      "[Test #47] Loss: 0.7562 Acc: 80.7709% Time: 1724.5852s\n",
      "Epoch 48 running\n",
      "[Train #48] Loss: 0.2821 Acc: 89.8150% Time: 1753.0302s\n",
      "[Test #48] Loss: 0.7245 Acc: 81.1991% Time: 1760.6630s\n",
      "Epoch 49 running\n",
      "[Train #49] Loss: 0.2662 Acc: 90.2830% Time: 1789.8904s\n",
      "[Test #49] Loss: 0.6813 Acc: 81.8844% Time: 1798.6375s\n",
      "Epoch 50 running\n",
      "[Train #50] Loss: 0.2674 Acc: 90.4613% Time: 1827.2853s\n",
      "[Test #50] Loss: 0.7297 Acc: 80.6424% Time: 1834.5577s\n",
      "Epoch 51 running\n",
      "[Train #51] Loss: 0.2671 Acc: 90.5282% Time: 1863.7818s\n",
      "[Test #51] Loss: 0.7588 Acc: 81.0278% Time: 1870.3949s\n",
      "Epoch 52 running\n",
      "[Train #52] Loss: 0.2628 Acc: 90.2162% Time: 1899.2318s\n",
      "[Test #52] Loss: 0.7884 Acc: 80.7709% Time: 1906.3206s\n",
      "Epoch 53 running\n",
      "[Train #53] Loss: 0.2437 Acc: 91.2636% Time: 1935.1118s\n",
      "[Test #53] Loss: 0.7593 Acc: 80.7709% Time: 1941.7058s\n",
      "Epoch 54 running\n",
      "[Train #54] Loss: 0.2587 Acc: 90.5059% Time: 1970.3044s\n",
      "[Test #54] Loss: 0.7260 Acc: 82.4411% Time: 1976.9313s\n",
      "Epoch 55 running\n",
      "[Train #55] Loss: 0.2717 Acc: 90.4613% Time: 2005.6947s\n",
      "[Test #55] Loss: 0.7774 Acc: 80.9850% Time: 2012.3499s\n",
      "Epoch 56 running\n",
      "[Train #56] Loss: 0.2290 Acc: 91.9991% Time: 2040.9862s\n",
      "[Test #56] Loss: 0.7220 Acc: 81.4561% Time: 2047.6300s\n",
      "Epoch 57 running\n",
      "[Train #57] Loss: 0.2343 Acc: 91.6202% Time: 2076.1295s\n",
      "[Test #57] Loss: 0.6967 Acc: 82.0128% Time: 2082.6171s\n",
      "Epoch 58 running\n",
      "[Train #58] Loss: 0.2547 Acc: 91.0408% Time: 2111.1470s\n",
      "[Test #58] Loss: 0.7391 Acc: 81.9700% Time: 2117.6053s\n",
      "Epoch 59 running\n",
      "[Train #59] Loss: 0.2347 Acc: 91.4865% Time: 2146.1800s\n",
      "[Test #59] Loss: 0.7410 Acc: 82.0985% Time: 2152.7808s\n",
      "Epoch 60 running\n",
      "[Train #60] Loss: 0.2277 Acc: 92.3334% Time: 2181.2650s\n",
      "[Test #60] Loss: 0.7744 Acc: 80.9422% Time: 2187.9241s\n",
      "Epoch 61 running\n",
      "[Train #61] Loss: 0.2210 Acc: 92.3111% Time: 2216.5708s\n",
      "[Test #61] Loss: 0.8716 Acc: 80.5996% Time: 2225.5033s\n",
      "Epoch 62 running\n",
      "[Train #62] Loss: 0.2167 Acc: 92.5340% Time: 2258.4814s\n",
      "[Test #62] Loss: 0.7183 Acc: 82.6124% Time: 2266.3476s\n",
      "Epoch 63 running\n",
      "[Train #63] Loss: 0.2483 Acc: 91.3974% Time: 2295.1605s\n",
      "[Test #63] Loss: 0.7042 Acc: 83.7687% Time: 2303.1548s\n",
      "Epoch 64 running\n",
      "[Train #64] Loss: 0.2495 Acc: 91.5088% Time: 2332.0904s\n",
      "[Test #64] Loss: 0.7892 Acc: 80.7281% Time: 2338.6586s\n",
      "Epoch 65 running\n",
      "[Train #65] Loss: 0.2330 Acc: 91.6648% Time: 2367.2521s\n",
      "[Test #65] Loss: 0.8042 Acc: 82.1413% Time: 2373.8951s\n",
      "Epoch 66 running\n",
      "[Train #66] Loss: 0.2431 Acc: 91.1745% Time: 2402.3588s\n",
      "[Test #66] Loss: 0.7790 Acc: 82.7409% Time: 2408.9655s\n",
      "Epoch 67 running\n",
      "[Train #67] Loss: 0.2202 Acc: 92.7569% Time: 2437.6219s\n",
      "[Test #67] Loss: 0.7238 Acc: 82.1413% Time: 2444.7111s\n",
      "Epoch 68 running\n",
      "[Train #68] Loss: 0.2228 Acc: 92.1105% Time: 2473.4306s\n",
      "[Test #68] Loss: 0.7309 Acc: 82.6552% Time: 2480.0405s\n",
      "Epoch 69 running\n",
      "[Train #69] Loss: 0.2355 Acc: 91.8431% Time: 2508.8775s\n",
      "[Test #69] Loss: 0.7775 Acc: 82.0985% Time: 2515.3584s\n",
      "Epoch 70 running\n",
      "[Train #70] Loss: 0.2262 Acc: 92.1551% Time: 2543.9191s\n",
      "[Test #70] Loss: 0.7652 Acc: 81.3705% Time: 2550.5491s\n",
      "Epoch 71 running\n",
      "[Train #71] Loss: 0.2266 Acc: 91.8431% Time: 2579.1539s\n",
      "[Test #71] Loss: 0.7079 Acc: 83.5118% Time: 2585.2447s\n",
      "Epoch 72 running\n",
      "[Train #72] Loss: 0.2107 Acc: 92.4671% Time: 2612.1015s\n",
      "[Test #72] Loss: 0.7419 Acc: 82.3555% Time: 2617.5700s\n",
      "Epoch 73 running\n",
      "[Train #73] Loss: 0.2085 Acc: 92.6231% Time: 2650.8430s\n",
      "[Test #73] Loss: 0.6955 Acc: 82.9122% Time: 2657.8288s\n",
      "Epoch 74 running\n",
      "[Train #74] Loss: 0.2273 Acc: 91.9545% Time: 2686.4356s\n",
      "[Test #74] Loss: 0.8219 Acc: 81.5846% Time: 2692.9981s\n",
      "Epoch 75 running\n",
      "[Train #75] Loss: 0.2229 Acc: 91.6871% Time: 2721.5549s\n",
      "[Test #75] Loss: 0.7250 Acc: 82.0128% Time: 2728.1739s\n",
      "Epoch 76 running\n",
      "[Train #76] Loss: 0.2141 Acc: 92.3780% Time: 2757.2492s\n",
      "[Test #76] Loss: 0.7336 Acc: 82.1842% Time: 2764.0717s\n",
      "Epoch 77 running\n",
      "[Train #77] Loss: 0.1874 Acc: 93.4700% Time: 2792.6615s\n",
      "[Test #77] Loss: 0.9216 Acc: 79.6146% Time: 2799.6077s\n",
      "Epoch 78 running\n",
      "[Train #78] Loss: 0.2055 Acc: 92.6677% Time: 2828.3429s\n",
      "[Test #78] Loss: 0.7346 Acc: 83.2120% Time: 2834.9634s\n",
      "Epoch 79 running\n",
      "[Train #79] Loss: 0.2096 Acc: 92.8906% Time: 2863.5143s\n",
      "[Test #79] Loss: 0.7153 Acc: 84.0257% Time: 2870.9355s\n",
      "Epoch 80 running\n",
      "[Train #80] Loss: 0.2026 Acc: 92.8906% Time: 2911.3565s\n",
      "[Test #80] Loss: 0.8199 Acc: 82.7837% Time: 2918.6430s\n",
      "Epoch 81 running\n",
      "[Train #81] Loss: 0.1943 Acc: 93.3586% Time: 2947.0637s\n",
      "[Test #81] Loss: 0.7314 Acc: 82.7409% Time: 2954.1725s\n",
      "Epoch 82 running\n",
      "[Train #82] Loss: 0.2067 Acc: 92.7569% Time: 2982.8721s\n",
      "[Test #82] Loss: 0.8270 Acc: 81.8415% Time: 2990.0260s\n",
      "Epoch 83 running\n",
      "[Train #83] Loss: 0.1975 Acc: 93.0689% Time: 3018.4914s\n",
      "[Test #83] Loss: 0.8173 Acc: 81.7559% Time: 3025.9682s\n",
      "Epoch 84 running\n",
      "[Train #84] Loss: 0.2089 Acc: 92.8237% Time: 3054.7283s\n",
      "[Test #84] Loss: 0.7674 Acc: 83.1263% Time: 3061.5688s\n",
      "Epoch 85 running\n",
      "[Train #85] Loss: 0.1929 Acc: 93.2472% Time: 3090.0811s\n",
      "[Test #85] Loss: 0.7327 Acc: 82.6552% Time: 3096.9485s\n",
      "Epoch 86 running\n",
      "[Train #86] Loss: 0.1921 Acc: 93.2694% Time: 3125.4913s\n",
      "[Test #86] Loss: 0.8107 Acc: 81.2848% Time: 3132.3374s\n",
      "Epoch 87 running\n",
      "[Train #87] Loss: 0.1882 Acc: 93.4700% Time: 3160.7680s\n",
      "[Test #87] Loss: 0.8066 Acc: 82.4839% Time: 3168.0255s\n",
      "Epoch 88 running\n",
      "[Train #88] Loss: 0.1875 Acc: 93.7375% Time: 3218.1469s\n",
      "[Test #88] Loss: 0.7529 Acc: 82.3126% Time: 3226.9692s\n",
      "Epoch 89 running\n",
      "[Train #89] Loss: 0.1718 Acc: 94.0940% Time: 3264.2577s\n",
      "[Test #89] Loss: 0.8010 Acc: 82.7409% Time: 3273.4453s\n",
      "Epoch 90 running\n",
      "[Train #90] Loss: 0.1856 Acc: 93.4700% Time: 3315.2652s\n",
      "[Test #90] Loss: 0.7574 Acc: 83.8544% Time: 3321.8511s\n",
      "Epoch 91 running\n",
      "[Train #91] Loss: 0.1866 Acc: 93.3363% Time: 3349.8608s\n",
      "[Test #91] Loss: 0.7726 Acc: 83.8116% Time: 3356.2705s\n",
      "Epoch 92 running\n",
      "[Train #92] Loss: 0.1827 Acc: 93.1134% Time: 3384.1489s\n",
      "[Test #92] Loss: 0.7196 Acc: 82.9550% Time: 3390.5684s\n",
      "Epoch 93 running\n",
      "[Train #93] Loss: 0.1889 Acc: 93.3586% Time: 3418.6129s\n",
      "[Test #93] Loss: 0.7762 Acc: 82.1413% Time: 3424.9700s\n",
      "Epoch 94 running\n",
      "[Train #94] Loss: 0.1738 Acc: 93.8712% Time: 3452.9693s\n",
      "[Test #94] Loss: 0.7645 Acc: 82.8265% Time: 3459.3422s\n",
      "Epoch 95 running\n",
      "[Train #95] Loss: 0.1761 Acc: 93.8489% Time: 3487.3822s\n",
      "[Test #95] Loss: 0.7134 Acc: 83.7259% Time: 3493.5813s\n",
      "Epoch 96 running\n",
      "[Train #96] Loss: 0.1685 Acc: 94.2055% Time: 3521.4798s\n",
      "[Test #96] Loss: 0.8305 Acc: 83.1263% Time: 3527.4929s\n",
      "Epoch 97 running\n",
      "[Train #97] Loss: 0.1742 Acc: 93.8266% Time: 3555.4586s\n",
      "[Test #97] Loss: 0.6753 Acc: 84.6681% Time: 3561.7392s\n",
      "Epoch 98 running\n",
      "[Train #98] Loss: 0.1830 Acc: 93.6483% Time: 3589.7269s\n",
      "[Test #98] Loss: 0.7119 Acc: 84.8822% Time: 3596.0436s\n",
      "Epoch 99 running\n",
      "[Train #99] Loss: 0.1747 Acc: 94.0940% Time: 3623.8826s\n",
      "[Test #99] Loss: 0.8794 Acc: 82.0985% Time: 3630.1027s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "train_losses = [] \n",
    "train_accs = []\n",
    "test_losses = []\n",
    "test_accs = []\n",
    "num_epochs = 100  # seta numero de epochs\n",
    "start_time = time.time() # calcular tempo de cada epoca\n",
    "for epoch in range(num_epochs): # loop para rodar as epocas\n",
    "    print(\"Epoch {} running\".format(epoch)) # printar epoca rodando\n",
    "    \"\"\" Training Phase \"\"\"\n",
    "    model.train()    # treinar modelo\n",
    "    running_loss = 0.   # zerando metricas\n",
    "    running_corrects = 0 # zerando metricas\n",
    "    # loop de imagem no treino, classificando imagem pelo rotulo\n",
    "    for i, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device) \n",
    "        # passando as entradas e obtendo resultado\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # obtendo valor da loss e atualizando os pesos da rede\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    train_losses.append(epoch_loss)\n",
    "    epoch_acc = running_corrects / len(train_dataset) * 100.\n",
    "    train_accs.append(epoch_acc)\n",
    "    print('[Train #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time() -start_time))\n",
    "    \n",
    "    \"\"\" Testing Phase \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        running_loss = 0.\n",
    "        running_corrects = 0\n",
    "        for inputs, labels in test_dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        epoch_loss = running_loss / len(test_dataset)\n",
    "        test_losses.append(epoch_loss) \n",
    "        epoch_acc = running_corrects / len(test_dataset) * 100.\n",
    "        test_accs.append(epoch_acc)\n",
    "        print('[Test #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time()- start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skincancer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
